import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as e,d as n,a as i,o}from"./app-RR3wWNiT.js";const l={},d={class:"MathJax",jax:"SVG",style:{position:"relative"}},s={style:{"vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.553ex",height:"1.557ex",role:"img",focusable:"false",viewBox:"0 -666 4222.4 688","aria-hidden":"true"};function Q(m,t){return o(),a("div",null,[t[4]||(t[4]=e("h1",{id:"autoencoder",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#autoencoder"},[e("span",null,"AutoEncoder")])],-1)),t[5]||(t[5]=e("h2",{id:"basic-idea",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#basic-idea"},[e("span",null,"Basic Idea")])],-1)),t[6]||(t[6]=e("p",null,"基于 deep learning 的降维算法。",-1)),t[7]||(t[7]=e("p",null,"模型由 encoder、decoder 构成，其中 encoder 用于将输入的高维向量编码到低维的 embedding，而 decoder 用于将 embedding 还原到原本的向量空间。",-1)),e("p",null,[t[2]||(t[2]=n("直观上讲，AutoEncoder 之所以能够实现，是因为输入样本的复杂度小于其向量空间维度。一个极端的例子是，对于 ")),e("mjx-container",d,[(o(),a("svg",s,t[0]||(t[0]=[i('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g></g></g>',1)]))),t[1]||(t[1]=e("mjx-assistive-mml",{unselectable:"on",display:"inline"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mn",null,"512"),e("mo",null,"×"),e("mn",null,"512")])],-1))]),t[3]||(t[3]=n(" 的图片，样本空间总共只有两张不同的图片，那么只需要 1 bit 就足以编码该样本空间。"))]),t[8]||(t[8]=e("p",null,"有了这个 embedding，就可以用来做一系列 downstream 的任务。",-1)),t[9]||(t[9]=e("blockquote",null,[e("p",null,"encoder、decoder的详细结构？")],-1)),t[10]||(t[10]=e("h2",{id:"usage",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#usage"},[e("span",null,"Usage")])],-1)),t[11]||(t[11]=e("ul",null,[e("li",null,"Feature Disentanglement：尝试将 embedding 拆分成不同部分，每个部分代表了输入的某一方面特征。例如，对于语音输入，尝试将 embedding 拆分为音色、内容两部分。可以应用到风格迁移中。"),e("li",null,"Discrete Representation：尝试用离散值（例如 01 编码、one-hot 编码）来表示 embedding。"),e("li",null,"...... （text as representation、tree as representation）")],-1))])}const c=r(l,[["render",Q],["__file","AutoEncoder.html.vue"]]),p=JSON.parse('{"path":"/work/cv/AutoEncoder.html","title":"AutoEncoder","lang":"en-US","frontmatter":{"cover":"/assets/images/work/cv/highres-lowram/cover.png","date":"2024-10-27T00:00:00.000Z","category":["article reading"],"tag":["Computer Vision","attention","transformer"],"star":true,"sticky":true,"excerpt":"<p>论文阅读笔记</p>","description":"AutoEncoder Basic Idea 基于 deep learning 的降维算法。 模型由 encoder、decoder 构成，其中 encoder 用于将输入的高维向量编码到低维的 embedding，而 decoder 用于将 embedding 还原到原本的向量空间。 直观上讲，AutoEncoder 之所以能够实现，是因为输入样本的...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://zhangmxxx.github.io/BlogSite/work/cv/AutoEncoder.html"}],["meta",{"property":"og:site_name","content":"Site MallocSimenons"}],["meta",{"property":"og:title","content":"AutoEncoder"}],["meta",{"property":"og:description","content":"AutoEncoder Basic Idea 基于 deep learning 的降维算法。 模型由 encoder、decoder 构成，其中 encoder 用于将输入的高维向量编码到低维的 embedding，而 decoder 用于将 embedding 还原到原本的向量空间。 直观上讲，AutoEncoder 之所以能够实现，是因为输入样本的..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://zhangmxxx.github.io/BlogSite/assets/images/work/cv/highres-lowram/cover.png"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://zhangmxxx.github.io/BlogSite/assets/images/work/cv/highres-lowram/cover.png"}],["meta",{"name":"twitter:image:alt","content":"AutoEncoder"}],["meta",{"property":"article:tag","content":"Computer Vision"}],["meta",{"property":"article:tag","content":"attention"}],["meta",{"property":"article:tag","content":"transformer"}],["meta",{"property":"article:published_time","content":"2024-10-27T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AutoEncoder\\",\\"image\\":[\\"https://zhangmxxx.github.io/BlogSite/assets/images/work/cv/highres-lowram/cover.png\\"],\\"datePublished\\":\\"2024-10-27T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MallocSimenons\\",\\"url\\":\\"https://zhangmxxx.github.io/BlogSite/intro.html\\"}]}"]]},"headers":[{"level":2,"title":"Basic Idea","slug":"basic-idea","link":"#basic-idea","children":[]},{"level":2,"title":"Usage","slug":"usage","link":"#usage","children":[]}],"readingTime":{"minutes":0.93,"words":278},"filePathRelative":"work/cv/AutoEncoder.md","localizedDate":"October 27, 2024","autoDesc":true}');export{c as comp,p as data};
